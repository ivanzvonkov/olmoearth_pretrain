"""Post-process ingested NAIP data into the Helios dataset."""

import argparse
import csv
import multiprocessing

import tqdm
from rslearn.data_sources import Item
from rslearn.dataset import Window
from rslearn.utils.mp import star_imap_unordered
from rslearn.utils.raster_format import GeotiffRasterFormat
from upath import UPath

from ..const import METADATA_COLUMNS

GROUPS = ["naip"]
BANDS = [
    "R",
    "G",
    "B",
    "IR",
]
LAYER_NAME = "naip"


def convert_naip(window_path: UPath, helios_path: UPath) -> None:
    """Add NAIP data for this window to the Helios dataset.

    Args:
        window_path: the rslearn window directory to read data from.
        helios_path: Helios dataset path to write to.
    """
    window = Window.load(window_path)
    layer_datas = window.load_layer_datas()
    raster_format = GeotiffRasterFormat()

    # NAIP is just one mosaic.
    item_groups = layer_datas[LAYER_NAME].serialized_item_groups
    if len(item_groups) == 0:
        return
    item_group = item_groups[0]

    # Get start and end of mosaic.
    start_time = None
    end_time = None
    for item_data in item_group:
        item = Item.deserialize(item_data)
        if start_time is None or item.geometry.time_range[0] < start_time:
            start_time = item.geometry.time_range[0]
        if end_time is None or item.geometry.time_range[1] > end_time:
            end_time = item.geometry.time_range[1]

    # Assert for type checking: we already checked that len(item_groups) > 0 so the
    # times should never be None.
    assert start_time is not None and end_time is not None  # nosec

    raster_dir = window.get_raster_dir(LAYER_NAME, BANDS)
    image = raster_format.decode_raster(raster_dir, window.bounds)
    raster_format.encode_raster(
        path=helios_path / "naip",
        projection=window.projection,
        bounds=window.bounds,
        array=image,
        fname=f"{window.name}.tif",
    )
    with (helios_path / "naip_meta" / f"{window.name}.csv").open("w") as f:
        writer = csv.DictWriter(f, fieldnames=METADATA_COLUMNS)
        writer.writeheader()
        writer.writerow(
            dict(
                example_id=window.name,
                image_idx="0",
                start_time=start_time.isoformat(),
                end_time=end_time.isoformat(),
            )
        )


if __name__ == "__main__":
    multiprocessing.set_start_method("forkserver")

    parser = argparse.ArgumentParser(
        description="Post-process Helios data",
    )
    parser.add_argument(
        "--ds_path",
        type=str,
        help="Source rslearn dataset path",
        required=True,
    )
    parser.add_argument(
        "--helios_path",
        type=str,
        help="Destination Helios dataset path",
        required=True,
    )
    parser.add_argument(
        "--workers",
        type=int,
        help="Number of workers to use",
        default=32,
    )
    args = parser.parse_args()

    ds_path = UPath(args.ds_path)
    helios_path = UPath(args.helios_path)

    jobs = []
    for group in GROUPS:
        metadata_fnames = (ds_path / "windows" / group).glob("*/metadata.json")
        for metadata_fname in metadata_fnames:
            jobs.append(
                dict(
                    window_path=metadata_fname.parent,
                    helios_path=helios_path,
                )
            )

    p = multiprocessing.Pool(args.workers)
    outputs = star_imap_unordered(p, convert_naip, jobs)
    for _ in tqdm.tqdm(outputs, total=len(jobs)):
        pass
    p.close()
