"""Sweeping across settings to find the best data loading times for galileo Tiny model."""

import itertools
import subprocess  # nosec

# Fixed model parameters
ENCODER_EMBEDDING_SIZE = 256
DECODER_EMBEDDING_SIZE = 256
ENCODER_DEPTH = 4
DECODER_DEPTH = 2
ENCODER_NUM_HEADS = 8
DECODER_NUM_HEADS = 8
MLP_RATIO = 4
LR = 1e-3
WD = 1e-2
WARMUP = 10
NUM_EPOCHS = 3
RANK_MICROBATCH_SIZE = 32

# SWEEP PARAMETERS
GLOBAL_BATCH_SIZES = [32, 64, 128, 256, 512]
NUM_WORKERS_OPTIONS = [8, 16, 32]
NUM_THREADS_OPTIONS = [0, 2, 4, 8]

# Base command template
BASE_COMMAND = (
    "python3 scripts/galileo.py launch {run_name} ai2/jupiter-cirrascale-2 "
    "--model.encoder_config.embedding_size={encoder_embedding_size} "
    "--model.encoder_config.depth={encoder_depth} "
    "--model.encoder_config.num_heads={encoder_num_heads} "
    "--model.encoder_config.mlp_ratio={mlp_ratio} "
    "--model.decoder_config.encoder_embedding_size={encoder_embedding_size} "
    "--model.decoder_config.decoder_embedding_size={decoder_embedding_size} "
    "--model.decoder_config.depth={decoder_depth} "
    "--model.decoder_config.num_heads={decoder_num_heads} "
    "--model.decoder_config.mlp_ratio={mlp_ratio} "
    "--data_loader.num_workers={num_workers} "
    "--data_loader.global_batch_size={global_batch_size} "
    "--train_module.rank_microbatch_size={rank_microbatch_size} "
    "--train_module.optim_config.lr={lr} "
    "--train_module.optim_config.weight_decay={wd} "
    "--train_module.warmup_duration.value={warmup} "
    "--train_module.warmup_duration.unit=epochs "
    "--trainer.max_duration.value={num_epochs} "
    "--trainer.max_duration.unit=epochs "
    "--data_loader.num_threads={num_threads} "
    "--launch.num_gpus={num_gpus}"
)

# Iterate over all combinations of hyperparameters
for global_batch_size, num_workers, num_threads in itertools.product(
    GLOBAL_BATCH_SIZES, NUM_WORKERS_OPTIONS, NUM_THREADS_OPTIONS
):
    # Construct run name indicating hyperparameters
    run_name = f"galileo_data_speed_gbs_{global_batch_size}_workers_{num_workers}_threads_{num_threads}"

    # Construct full command
    command = BASE_COMMAND.format(
        run_name=run_name,
        encoder_embedding_size=ENCODER_EMBEDDING_SIZE,
        decoder_embedding_size=DECODER_EMBEDDING_SIZE,
        encoder_depth=ENCODER_DEPTH,
        decoder_depth=DECODER_DEPTH,
        encoder_num_heads=ENCODER_NUM_HEADS,
        decoder_num_heads=DECODER_NUM_HEADS,
        mlp_ratio=MLP_RATIO,
        num_workers=num_workers,
        global_batch_size=global_batch_size,
        rank_microbatch_size=RANK_MICROBATCH_SIZE,
        lr=LR,
        wd=WD,
        warmup=WARMUP,
        num_epochs=NUM_EPOCHS,
        num_threads=num_threads,
        num_gpus=1,
    )

    print(f"Launching: {command}")

    # Execute the command
    subprocess.run(command, shell=True, check=True)  # nosec
